>[!note] Gradient Descent and The Gradient Vector
>We may use an iterative algorithm, known as gradient descent, to numerically compute the optimal value of $\theta$ where the loss of a [[4.2c.1 Multiple Linear Regression|linear regression]] model is minimized by guesstimating the minimum until we converge to the real minimum value such that
>$$\theta_{t+1}=\theta_t - \alpha\frac{d}{d\theta}L(\theta_t),$$
>where $\alpha$ is the learning rate (or the magnitude of the steps).
>
>
>In doing so for multivariate models, we may generalize the gradient descent process for $n$ minimum theta values $\vec{\theta}=\begin{bmatrix}\hat{\theta}_0 \\ \vdots \\ \hat{\theta}_n\end{bmatrix}$ as
>$$\vec{\theta}_{t+1}=\vec{\theta}_t-\nabla_\vec{\theta}L(\theta_t),$$
>where $\nabla_\vec{\theta}L(\theta_t)=\begin{bmatrix}\frac{\partial}{\partial\theta_0} \\ \dots \\ \partial\theta_n\end{bmatrix}$ is the gradient vector.
>>[!warning] Convexity of the Loss Function
>>If our loss function is not convex (has more than one local minimum), choosing the wrong $\theta_G$ may lead to convergence to the wrong minimum.

# Intuition
Suppose we start at an optimal value of $\theta_G=\theta_0$. Since our guess $\theta_0 \neq \hat{\theta}$, we can split our guess into two cases:
1. The guess $\theta_0$ "undershoots" $\hat{\theta}$ ($\theta_G < \hat{\theta}$).
	- The derivative of our loss function will be **negative**, so we must **increase** our guess by moving in the positive direction of $\theta$ until $\theta_G \to \hat{\theta}$.
2. The guess $\theta_0$ "overshoots" $\hat{\theta}$ ($\theta_G > \hat{\theta}$).
	- The derivative of our loss function will be **positive**, so we must **decrease** our guess until $\theta_G \to \hat{\theta}$.
